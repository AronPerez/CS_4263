{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "B9lJ3gKBmJtl",
        "hh06Cd0nmdNc"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qTz1FgTDa8O"
      },
      "source": [
        "# Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mSj7BXPDjgs",
        "outputId": "f76ff3dc-299f-4ca0-d6e9-116e918230d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x6SERkaDlmO",
        "outputId": "ef0aca91-9c13-41bd-85e1-c03e749c7c42"
      },
      "source": [
        "!pip install zarr\n",
        "!pip install l5kit\n",
        "!pip install colorama\n",
        "!pip install -U PyYAML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting zarr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/ae/653da881ff4281d5d59b3901e13a2127182e8679db10b322365588d43111/zarr-2.7.0-py3-none-any.whl (137kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 5.6MB/s \n",
            "\u001b[?25hCollecting asciitree\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/6a/885bc91484e1aa8f618f6f0228d76d0e67000b0fdd6090673b777e311913/asciitree-0.3.3.tar.gz\n",
            "Collecting numcodecs>=0.6.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/fa/a4450b9b6bac850d65316d00a1417e633fc0fe36d66cc6407640242cd8e4/numcodecs-0.7.3-cp37-cp37m-manylinux2010_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from zarr) (1.19.5)\n",
            "Collecting fasteners\n",
            "  Downloading https://files.pythonhosted.org/packages/78/20/c862d765287e9e8b29f826749ebae8775bdca50b2cb2ca079346d5fbfd76/fasteners-0.16-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners->zarr) (1.15.0)\n",
            "Building wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-cp37-none-any.whl size=5037 sha256=a5b7b68e88ee0e5f50dea34ceaa6914ca9a3921939af653ec1a4aaceda0d93e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/d9/58/9808b306744df0208fccc640d3d9952a5bc7468502d42897d5\n",
            "Successfully built asciitree\n",
            "Installing collected packages: asciitree, numcodecs, fasteners, zarr\n",
            "Successfully installed asciitree-0.3.3 fasteners-0.16 numcodecs-0.7.3 zarr-2.7.0\n",
            "Collecting l5kit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c3/439baa825240852785ae74cf5442a174256fd5b2df5f7170e5913fad80dd/l5kit-1.2.0-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.1MB/s \n",
            "\u001b[?25hCollecting pymap3d\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/a3/79f7d175f6f86bd9146d660cb336ee9de273edcd32811d07bfa5cbe498ac/pymap3d-2.6.0.tar.gz (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 6.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch<2.0.0,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.8.1+cu101)\n",
            "Collecting ptable\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/b3/b54301811173ca94119eb474634f120a49cd370f257d1aae5a4abaf12729/PTable-0.9.2.tar.gz\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from l5kit) (7.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from l5kit) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.4.1)\n",
            "Collecting opencv-contrib-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/92/4b67b838963e5702ab5d452a1f8ad0918c2ce12d191e4ca7fa60fdb3d4ea/opencv_contrib_python_headless-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (43.6MB)\n",
            "\u001b[K     |████████████████████████████████| 43.6MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.7.1)\n",
            "Collecting transforms3d\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/f7/e85809168a548a854d7c1331560c27b4f5381698d29c12e57759192b2bc1/transforms3d-0.3.1.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision<1.0.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from l5kit) (0.9.1+cu101)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.7/dist-packages (from l5kit) (2.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from l5kit) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from l5kit) (3.13)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from l5kit) (5.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from l5kit) (54.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from l5kit) (3.12.4)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from l5kit) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.5.0->l5kit) (3.7.4.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (1.0.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (5.0.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (5.1.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (4.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->l5kit) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->l5kit) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->l5kit) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->l5kit) (2.4.7)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.6.0->l5kit) (7.1.2)\n",
            "Requirement already satisfied: numcodecs>=0.6.4 in /usr/local/lib/python3.7/dist-packages (from zarr->l5kit) (0.7.3)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.7/dist-packages (from zarr->l5kit) (0.16)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.7/dist-packages (from zarr->l5kit) (0.3.3)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (5.3.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (5.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (0.9.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (2.11.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (5.1.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (1.5.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (4.7.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->l5kit) (1.15.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->l5kit) (2.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (2.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook->l5kit) (22.0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->l5kit) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->l5kit) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->l5kit) (0.2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->l5kit) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->l5kit) (20.9)\n",
            "Building wheels for collected packages: pymap3d\n",
            "  Building wheel for pymap3d (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymap3d: filename=pymap3d-2.6.0-cp37-none-any.whl size=50119 sha256=88eddd345e0828494f8e7f15bbd032bd79802ea0753baf9581a3c3a0d31029f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/47/77/85ddae5d29443cda2ce5c9f8079e1d84052c53be6c44fe5cb4\n",
            "Successfully built pymap3d\n",
            "Building wheels for collected packages: ptable, transforms3d\n",
            "  Building wheel for ptable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptable: filename=PTable-0.9.2-cp37-none-any.whl size=22906 sha256=893b686b8009377131a985944949277a67778b7141c1a33e57b2fd8af810f1b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/cc/2e/55980bfe86393df3e9896146a01f6802978d09d7ebcba5ea56\n",
            "  Building wheel for transforms3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transforms3d: filename=transforms3d-0.3.1-cp37-none-any.whl size=59374 sha256=f4e659ebd13e052e14d5bac845d33ad3e88f0c2d023eafa11112d08483434f5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/3c/84/28d36677f3c760c048bd02b5a547ea0c4027770cc9cdb9af1e\n",
            "Successfully built ptable transforms3d\n",
            "Installing collected packages: pymap3d, ptable, opencv-contrib-python-headless, transforms3d, l5kit\n",
            "Successfully installed l5kit-1.2.0 opencv-contrib-python-headless-4.5.1.48 ptable-0.9.2 pymap3d-2.6.0 transforms3d-0.3.1\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n",
            "Collecting PyYAML\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 5.6MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4cFMQC7DnXW"
      },
      "source": [
        "import os, gc\n",
        "import zarr\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import l5kit\n",
        "import psutil\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import pprint\n",
        "from tqdm import tqdm\n",
        "import tqdm.notebook as tq\n",
        "from typing import Dict\n",
        "from collections import Counter\n",
        "from prettytable import PrettyTable\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "\n",
        "#level5 toolkit\n",
        "from l5kit.data import labels\n",
        "from l5kit.dataset import EgoDataset, AgentDataset\n",
        "from l5kit.data import ChunkedDataset, LocalDataManager\n",
        "\n",
        "# level5 toolkit \n",
        "from l5kit.configs import load_config_data\n",
        "from l5kit.geometry import transform_points\n",
        "from l5kit.rasterization import build_rasterizer\n",
        "from l5kit.visualization import draw_trajectory, draw_reference_trajectory, TARGET_POINTS_COLOR\n",
        "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
        "from l5kit.evaluation import *\n",
        "from l5kit.kinematic import AckermanPerturbation\n",
        "from l5kit.random import GaussianRandomGenerator\n",
        "\n",
        "# visualization\n",
        "from matplotlib import animation\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "# deep learning\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.resnet import resnet18, resnet50, resnet34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcnoar5wDo4p"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    \n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuHUJwlWDvRI",
        "outputId": "2a63931f-7d21-47f3-d0c4-a11e87fd2f6c"
      },
      "source": [
        "# set env variable for data\n",
        "# Aaron P DIR_INPUT = \"/content/Dataset/lyft-motion-prediction-autonomous-vehicles/\"\n",
        "# Default \"./content/drive/MyDrive/lyft-motion-prediction-autonomous-vehicles/\"\n",
        "# Config.yaml need to be manually uploaded to /content/\n",
        "!pwd\n",
        "DIR_INPUT = \"/content/drive/MyDrive/lyft-motion-prediction-autonomous-vehicles/\"\n",
        "cfg = load_config_data(\"/content/drive/MyDrive/lyft-motion-prediction-autonomous-vehicles/config.yaml\")\n",
        "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
        "dm = LocalDataManager(None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYtP2tO_EJvC"
      },
      "source": [
        "# == Init Test Dataset ==\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJjKHt4wTcqT",
        "outputId": "264ea32e-c2f1-4665-c47b-1f20c5aeb63b"
      },
      "source": [
        "test_cfg = cfg[\"test_data_loader\"]\n",
        "rasterizer = build_rasterizer(cfg, dm)\n",
        "\n",
        "\n",
        "test_zarr = ChunkedDataset(dm.require(test_cfg[\"key\"])).open()\n",
        "test_mask = np.load(f\"{DIR_INPUT}/scenes/mask.npz\")[\"arr_0\"]\n",
        "\n",
        "test_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)\n",
        "\n",
        "#test_dataset = EgoDataset(cfg, test_zarr, rasterizer, perturbation) #Artifically applies agents\n",
        "test_dataloader = DataLoader(test_dataset,shuffle=test_cfg[\"shuffle\"],batch_size=test_cfg[\"batch_size\"],\n",
        "                             num_workers=test_cfg[\"num_workers\"])\n",
        "print(\"==================================TEST DATA==================================\")\n",
        "print(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================TEST DATA==================================\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|   11314    |  1131400   |  88594921  |    7854144    |      31.43      |        100.00        |        78.31         |        10.00         |        10.00        |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwINF1izEZ7H"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOY8342nEc_Z"
      },
      "source": [
        "from torch import Tensor\n",
        "def pytorch_neg_multi_log_likelihood_batch(\n",
        "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "    Compute a negative log-likelihood for the multi-modal scenario.\n",
        "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
        "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
        "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
        "    https://leimao.github.io/blog/LogSumExp/\n",
        "    Args:\n",
        "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
        "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
        "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
        "    Returns:\n",
        "        Tensor: negative log-likelihood for this example, a single float number\n",
        "    \"\"\"\n",
        "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
        "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
        "\n",
        "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
        "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
        "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
        "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
        "    # assert all data are valid\n",
        "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
        "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
        "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
        "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
        "\n",
        "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
        "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
        "    avails = avails[:, None, :, None]  # add modes and cords\n",
        "\n",
        "    # error (batch_size, num_modes, future_len)\n",
        "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
        "\n",
        "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
        "        # error (batch_size, num_modes)\n",
        "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
        "\n",
        "    # use max aggregator on modes for numerical stability\n",
        "    # error (batch_size, num_modes)\n",
        "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
        "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
        "    # print(\"error\", error)\n",
        "    return torch.mean(error)\n",
        "\n",
        "\n",
        "def pytorch_neg_multi_log_likelihood_single(\n",
        "    gt: Tensor, pred: Tensor, avails: Tensor\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
        "    Returns:\n",
        "        Tensor: negative log-likelihood for this example, a single float number\n",
        "    \"\"\"\n",
        "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
        "    # create confidence (bs)x(mode=1)\n",
        "    batch_size, future_len, num_coords = pred.shape\n",
        "    confidences = pred.new_ones((batch_size, 1))\n",
        "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBT0lqcCEejc"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6nh6G6wEmDa"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg: Dict, num_modes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
        "        backbone = eval(architecture)(pretrained=True, progress=True)\n",
        "        self.backbone = backbone\n",
        "\n",
        "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
        "        num_in_channels = 3 + num_history_channels\n",
        "\n",
        "        self.backbone.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                num_in_channels, \n",
        "                self.backbone.conv1.out_channels, \n",
        "                kernel_size=self.backbone.conv1.kernel_size,\n",
        "                stride=self.backbone.conv1.stride,\n",
        "                padding=self.backbone.conv1.padding,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.ReLU(), # Added ReLU\n",
        "            nn.MaxPool2d(kernel_size=self.backbone.conv1.kernel_size), #Pooling layer\n",
        "        )\n",
        "\n",
        "        # This is 512 for resnet18 and resnet34;\n",
        "        # And it is 2048 for the other resnets\n",
        "        \n",
        "        if architecture == \"resnet50\":\n",
        "            backbone_out_features = 2048\n",
        "        else:\n",
        "            backbone_out_features = 512\n",
        "\n",
        "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
        "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
        "        num_targets = 2 * self.future_len\n",
        "\n",
        "        # You can add more layers here.\n",
        "        self.head = nn.Sequential(\n",
        "            # nn.Dropout(0.2),\n",
        "            nn.Linear(in_features=backbone_out_features, out_features=4096),\n",
        "        )\n",
        "\n",
        "        self.num_preds = num_targets * num_modes\n",
        "        self.num_modes = num_modes\n",
        "\n",
        "        self.logit = nn.Linear(4096, out_features=self.num_preds + num_modes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        x = self.backbone.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.head(x)\n",
        "        x = self.logit(x)\n",
        "\n",
        "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
        "        # confidences (batch_size)x(modes)\n",
        "        bs, _ = x.shape\n",
        "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
        "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
        "        assert confidences.shape == (bs, self.num_modes)\n",
        "        confidences = torch.softmax(confidences, dim=1)\n",
        "        return pred, confidences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NOn_sE7EnFK"
      },
      "source": [
        "def forward(data, model, device, criterion = pytorch_neg_multi_log_likelihood_batch):\n",
        "    inputs = data[\"image\"].to(device)\n",
        "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
        "    targets = data[\"target_positions\"].to(device)\n",
        "    # Forward pass\n",
        "    preds, confidences = model(inputs)\n",
        "    loss = criterion(targets, preds, confidences, target_availabilities)\n",
        "    return loss, preds, confidences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRKg9JDOEqOE"
      },
      "source": [
        "# == Init Model =="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nLJM3vHEtKq",
        "outputId": "b0fe916b-5c7c-4bcb-fc05-39d15cb03c21"
      },
      "source": [
        "import copy\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model(cfg)\n",
        "print(cfg[\"model_params\"][\"weight_path\"])\n",
        "#load weight if there is a pretrained model\n",
        "weight_path = cfg[\"model_params\"][\"weight_path\"]\n",
        "if weight_path != \"None\": #https://stackoverflow.com/questions/56369030/runtimeerror-attempting-to-deserialize-object-on-a-cuda-device\n",
        "    torch.save(model.state_dict(),weight_path)\n",
        "    model.load_state_dict(copy.deepcopy(torch.load('/content/drive/MyDrive/lyft-motion-prediction-autonomous-vehicles/models/planning_model.pt', device)))\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "print(f'device {device}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/lyft-motion-prediction-autonomous-vehicles/models/model_multi_update_lyft_public.pth\n",
            "device cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTKOczPkFlkb"
      },
      "source": [
        "# Eval Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7YJYp6yFrC1",
        "outputId": "bd5bdac2-bc41-4e81-afba-4402797b79d9"
      },
      "source": [
        "if cfg[\"model_params\"][\"predict\"]:\n",
        "    \n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "    # store information for evaluation\n",
        "    future_coords_offsets_pd = []\n",
        "    timestamps = []\n",
        "    confidences_list = []\n",
        "    agent_ids = []\n",
        "\n",
        "    progress_bar = tqdm(test_dataloader)\n",
        "    \n",
        "    for data in progress_bar:\n",
        "        \n",
        "        _, preds, confidences = forward(data, model, device)\n",
        "    \n",
        "        #fix for the new environment\n",
        "        preds = preds.cpu().numpy()\n",
        "        world_from_agents = data[\"world_from_agent\"].numpy()\n",
        "        centroids = data[\"centroid\"].numpy()\n",
        "        coords_offset = []\n",
        "        \n",
        "        # convert into world coordinates and compute offsets\n",
        "        for idx in range(len(preds)):\n",
        "            for mode in range(3):\n",
        "                preds[idx, mode, :, :] = transform_points(preds[idx, mode, :, :], world_from_agents[idx]) - centroids[idx][:2]\n",
        "    \n",
        "        future_coords_offsets_pd.append(preds.copy())\n",
        "        confidences_list.append(confidences.cpu().numpy().copy())\n",
        "        timestamps.append(data[\"timestamp\"].numpy().copy())\n",
        "        agent_ids.append(data[\"track_id\"].numpy().copy()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2223/2223 [30:08<00:00,  1.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46gRGecVFvGW"
      },
      "source": [
        "### Now that we've successfully made predictions based on our model, we'll put them into our CSV\n",
        "From here, we can parse and make interpretations on the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DWC1n-iFucT"
      },
      "source": [
        "pred_path = './submission_r1_1000i.csv'\n",
        "write_pred_csv(pred_path,\n",
        "           timestamps=np.concatenate(timestamps),\n",
        "           track_ids=np.concatenate(agent_ids),\n",
        "           coords=np.concatenate(future_coords_offsets_pd),\n",
        "           confs = np.concatenate(confidences_list)\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}